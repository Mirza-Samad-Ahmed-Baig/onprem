{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hf.tensors\n",
    "\n",
    "> PyTorch utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp hf.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Pipeline module\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    \"\"\"\n",
    "    Base class for all Pipelines. The only interface requirement is to define a __call___ method.\n",
    "    \"\"\"\n",
    "\n",
    "    def batch(self, data, size):\n",
    "        \"\"\"\n",
    "        Splits data into separate batch sizes specified by size.\n",
    "\n",
    "        Args:\n",
    "            data: data elements\n",
    "            size: batch size\n",
    "\n",
    "        Returns:\n",
    "            list of evenly sized batches with the last batch having the remaining elements\n",
    "        \"\"\"\n",
    "\n",
    "        return [data[x : x + size] for x in range(0, len(data), size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\"\"\"\n",
    "Tensor processing framework module\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class Tensors(Pipeline):\n",
    "    \"\"\"\n",
    "    Pipeline backed by a tensor processing framework. Currently supports PyTorch.\n",
    "    \"\"\"\n",
    "\n",
    "    def quantize(self, model):\n",
    "        \"\"\"\n",
    "        Quantizes input model and returns. This only is supported for CPU devices.\n",
    "\n",
    "        Args:\n",
    "            model: torch model\n",
    "\n",
    "        Returns:\n",
    "            quantized torch model\n",
    "        \"\"\"\n",
    "\n",
    "        # pylint: disable=E1101\n",
    "        return torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "\n",
    "    def tensor(self, data):\n",
    "        \"\"\"\n",
    "        Creates a tensor array.\n",
    "\n",
    "        Args:\n",
    "            data: input data\n",
    "\n",
    "        Returns:\n",
    "            tensor\n",
    "        \"\"\"\n",
    "\n",
    "        # pylint: disable=E1102\n",
    "        return torch.tensor(data)\n",
    "\n",
    "    def context(self):\n",
    "        \"\"\"\n",
    "        Defines a context used to wrap processing with the tensor processing framework.\n",
    "\n",
    "        Returns:\n",
    "            processing context\n",
    "        \"\"\"\n",
    "\n",
    "        # pylint: disable=E1101\n",
    "        return torch.no_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
