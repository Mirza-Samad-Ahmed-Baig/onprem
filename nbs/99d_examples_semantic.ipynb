{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying vector database in [OnPrem.LLM](https://github.com/amaiya/onprem) can be used for detecting semantic similarity among pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (3904) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "import os, tempfile\n",
    "from onprem import LLM\n",
    "\n",
    "vectordb_path = tempfile.mkdtemp()\n",
    "llm = LLM(\n",
    "    embedding_model_name=\"sentence-transformers/nli-mpnet-base-v2\",\n",
    "    embedding_encode_kwargs={\"normalize_embeddings\": True},\n",
    "    vectordb_path=vectordb_path,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "data = [  # from txtai\n",
    "    \"US tops 5 million confirmed virus cases\",\n",
    "    \"Canada's last fully intact ice shelf has suddenly collapsed, forming a Manhattan-sized iceberg\",\n",
    "    \"Beijing mobilises invasion craft along coast as Taiwan tensions escalate\",\n",
    "    \"The National Park Service warns against sacrificing slower friends in a bear attack\",\n",
    "    \"Maine man wins $1M from $25 lottery ticket\",\n",
    "    \"Make huge profits without work, earn up to $100,000 a day\",\n",
    "]\n",
    "source_folder = tempfile.mkdtemp()\n",
    "for i, d in enumerate(data):\n",
    "    filename = os.path.join(source_folder, f\"doc{i}.txt\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cfe7bc69264090aa824f89c6b1b635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vectorstore at /tmp/tmp3hfoghhl\n",
      "Loading documents from /tmp/tmpd656fsvo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading new documents: 100%|████████████████████| 6/6 [00:00<00:00, 1863.31it/s]\n",
      "Processing and chunking 6 new documents: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2068.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 6 chunks of text (max. 500 chars each for text; max. 2000 chars for tables)\n",
      "Creating embeddings. May take some minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion complete! You can now query your documents using the LLM.ask or LLM.chat methods\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "llm.ingest(source_folder, chunk_size=500, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we get a reference to the underlying vector store and query it directly to find the best semantic match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feel good story : Maine man wins $1M from $25 lottery ticket\n",
      "climate change : Canada's last fully intact ice shelf has suddenly collapsed, forming a Manhattan-sized iceberg\n",
      "public health story : US tops 5 million confirmed virus cases\n",
      "war : Beijing mobilises invasion craft along coast as Taiwan tensions escalate\n",
      "wildlife : The National Park Service warns against sacrificing slower friends in a bear attack\n",
      "asia : Beijing mobilises invasion craft along coast as Taiwan tensions escalate\n",
      "lucky : Maine man wins $1M from $25 lottery ticket\n",
      "dishonest junk : Make huge profits without work, earn up to $100,000 a day\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "vs = llm.load_vectorstore()\n",
    "for query in (\n",
    "    \"feel good story\",\n",
    "    \"climate change\",\n",
    "    \"public health story\",\n",
    "    \"war\",\n",
    "    \"wildlife\",\n",
    "    \"asia\",\n",
    "    \"lucky\",\n",
    "    \"dishonest junk\",\n",
    "):\n",
    "    docs = vs.query(query)\n",
    "    print(f\"{query} : {docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
