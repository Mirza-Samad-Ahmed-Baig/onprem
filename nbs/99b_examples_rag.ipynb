{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talk to Your Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example of [OnPrem.LLM](https://github.com/amaiya/onprem) demonstrates retrieval augmented generation or RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the `LLM` instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use a model called **[Zephyr-7B-beta](https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF)**, which [performs well on RAG tasks](https://www.rungalileo.io/hallucinationindex).  When selecting a model, it is important to inspect the model's home page and identify the correct prompt format.  The prompt format for this model is [located here](https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF#prompt-template-zephyr), and we will supply it directly to the `LLM` constructor along with the URL to the specific model file we want (i.e., *zephyr-7b-beta.Q4_K_M.gguf*).  We will offload layers to our GPU(s) to speed up inference using the `n_gpu_layers` parameter. (For more information on GPU acceleration, see [here](https://amaiya.github.io/onprem/#speeding-up-inference-using-a-gpu).) For the purposes of this notebook, we also supply `temperature=0` so that there is no variability in outputs.  You can increase this value for more creativity in the outputs. Finally, we will choose a non-default location for our vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "from onprem import LLM, utils as U\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (3904) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "vectordb_path = tempfile.mkdtemp()\n",
    "\n",
    "llm = LLM(model_url='https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/resolve/main/zephyr-7b-beta.Q4_K_M.gguf', \n",
    "          prompt_template= \"<|system|>\\n</s>\\n<|user|>\\n{prompt}</s>\\n<|assistant|>\",\n",
    "          n_gpu_layers=-1,\n",
    "          temperature=0,\n",
    "          store_type='dense',\n",
    "          vectordb_path=vectordb_path,\n",
    "         verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since OnPrem.LLM includes built-in support for Zephyr, an easier way to instantiate the LLM with Zephyr is as follows:\n",
    "\n",
    "```python\n",
    "llm = LLM(default_model='zephyr', \n",
    "          n_gpu_layers=-1,\n",
    "          temperature=0,\n",
    "          store_type='dense',\n",
    "          vectordb_path=vectordb_path)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Documents\n",
    "\n",
    "When ingesting documents, they can be stored in one of two ways:\n",
    "1. a **dense** vector store:  a conventional vector database like Chroma\n",
    "2. a **sparse** vector store: a keyword-search engine\n",
    "\n",
    "Sparse vector stores compute embeddings on-the-fly at inference time. As a result, sparse vector stores sacrifice a small amount of inference speed for significant speed ups in ingestion speed.  This makes it better suited for larger document sets.  Note that sparse vector stores include the contraint that any passages considered as sources for answers should have at least one word in common with the question being asked. You can specify the kind of vector store by supplying either `store_type=\"dense\"` or `store_type=\"sparse\"` when creating the `LLM` above.  We use a dense vector store in this example, as shown above.\n",
    "\n",
    "For this example, we will download the 2024 National Defense Autorization Act (NDAA) report and ingest it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[██████████████████████████████████████████████████]"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "U.download('https://www.congress.gov/118/crpt/hrpt125/CRPT-118hrpt125.pdf', '/tmp/ndaa/ndaa.pdf', verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vectorstore at /tmp/tmp076q1l40/dense\n",
      "Loading documents from /tmp/ndaa/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading new documents: 100%|██████████████████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "Processing and chunking 672 new documents: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 5202 chunks of text (max. 500 chars each for text; max. 2000 chars for tables)\n",
      "Creating embeddings. May take some minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:17<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion complete! You can now query your documents using the LLM.ask or LLM.chat methods\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "llm.ingest(\"/tmp/ndaa/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking Questions to Your Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The context provided discusses the implementation of an AI education strategy required by Section 256 of the National Defense Authorization Act for Fiscal Year 2020. The strategy aims to educate servicemembers in relevant occupational fields, with a focus on data literacy across a broader population within the Department of Defense. The committee encourages the Air Force and Space Force to leverage government-owned training platforms informed by private sector expertise to accelerate learning and career path development. Additionally, the committee suggests expanding existing mobile enabled platforms to train and develop the cyber workforce of the Air Force and Space Force. Overall, there is a recognition that AI continues to be central to warfighting and that proper implementation of these new technologies requires a focus on education and training."
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "result = llm.ask(\"What is said about artificial intelligence training and education?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is stored in `results['answer']`. The documents retrieved from the vector store used to generate the answer are stored in `results['source_documents']` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REFERENCES\n",
      "\n",
      "On Page 359 in /tmp/ndaa/ndaa.pdf:\n",
      "‘‘servicemembers in relevant occupational fields on matters relating \n",
      "to artificial intelligence.’’ \n",
      "Given the continued centrality of AI to warfighting, the com-\n",
      "mittee directs the Chief Digital and Artificial Intelligence Officer of \n",
      "the Department of Defense to provide a briefing to the House Com-\n",
      "mittee on Armed Services not later than March 31, 2024, on the \n",
      "implementation status of the AI education strategy, with emphasis \n",
      "on current efforts underway, such as the AI Primer course within\n",
      "----------------------------------------\n",
      "\n",
      "On Page 359 in /tmp/ndaa/ndaa.pdf:\n",
      "intelligence (AI) and machine learning capabilities available within \n",
      "the Department of Defense. To ensure the proper implementation \n",
      "of these new technologies, there must be a focus on data literacy \n",
      "across a broader population within the Department. Section 256 of \n",
      "the National Defense Authorization Act for Fiscal Year 2020 (Pub-\n",
      "lic Law 116–92) required the Department of Defense to develop an \n",
      "AI education strategy, with the stated objective to educate\n",
      "----------------------------------------\n",
      "\n",
      "On Page 102 in /tmp/ndaa/ndaa.pdf:\n",
      "tificial intelligence and machine learning (AI/ML), and cloud com-\n",
      "puting. The committee encourages the Air Force and Space Force \n",
      "to leverage government owned training platforms with curricula in-\n",
      "formed by private sector expertise to accelerate learning and career \n",
      "path development. \n",
      "To that end, the committee encourages the Secretary of the Air \n",
      "Force to expand existing mobile enabled platforms to train and de-\n",
      "velop the cyber workforce of Air Force and Space Force. To better\n",
      "----------------------------------------\n",
      "\n",
      "On Page 109 in /tmp/ndaa/ndaa.pdf:\n",
      "70 \n",
      "role of senior official with principal responsibility for artificial intel-\n",
      "ligence and machine learning. In February 2022, the Department \n",
      "stood up the Chief Digital and Artificial Intelligence Office to accel-\n",
      "erate the Department’s adoption of AI. The committee encourages \n",
      "the Department to build upon this progress and sustain efforts to \n",
      "research, develop, test, and where appropriate, operationalize AI \n",
      "capabilities. \n",
      "Artificial intelligence capabilities of foreign adversaries\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "\n",
    "print('REFERENCES')\n",
    "print()\n",
    "for d in result['source_documents']:\n",
    "    print(f\"On Page {d.metadata['page']} in {d.metadata['source']}:\")\n",
    "    print(d.page_content)\n",
    "    print('----------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The context provided highlights the importance of expanding and fully funding programs related to hypersonic technology. The House Committee on Armed Services has directed the Secretary of Defense to submit a report by December 1, 2023, detailing efforts to ensure the development and sustainment of a future hypersonic workforce. The committee notes concerns about advancements in hypersonic capabilities made by peer and near-peer adversaries, emphasizing the need for investments to enhance the ability to develop, test, and field advanced hypersonic capabilities. The lack of research and development funding directed towards fielding a reusable hypersonic platform with aircraft-like operations and qualities is also raised as a concern. To address this issue, the committee directs the Under Secretary of Defense to develop graduate and pre-doctoral degree programs for the hypersonics workforce and increase funding for advanced hypersonics facilities for research and graduate-level education. Innovation organizations are also identified as important in this context. Overall, the provided context highlights the significance of hypersonic technology and the need for continued investment and development in this area."
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "result = llm.ask(\"What is said about hypersonics?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REFERENCES\n",
      "\n",
      "On Page 120 in /tmp/ndaa/ndaa.pdf:\n",
      "lieves those programs should be expanded and fully funded, par-\n",
      "ticularly in the field of hypersonic technology. \n",
      "Therefore, the committee directs the Secretary of Defense to sub-\n",
      "mit a report to the House Committee on Armed Services not later \n",
      "than December 1, 2023, on the Department’s efforts to ensure the \n",
      "development and sustainment of its future hypersonic workforce. \n",
      "The report shall include: \n",
      "(1) an overview of hypersonic workforce development objectives\n",
      "----------------------------------------\n",
      "\n",
      "On Page 81 in /tmp/ndaa/ndaa.pdf:\n",
      "velopment of carbon-carbon high temperature composites for \n",
      "hypersonic weapons. \n",
      "Hypersonics test infrastructure \n",
      "The committee notes with concern the advancements in \n",
      "hypersonic capabilities made by peer and near-peer adversaries. To \n",
      "ensure the U.S. military can effectively deter and, if necessary, de-\n",
      "feat these national security threats, the Department of Defense \n",
      "must make investments to enhance its ability to develop, test, and \n",
      "field advanced hypersonic capabilities.\n",
      "----------------------------------------\n",
      "\n",
      "On Page 127 in /tmp/ndaa/ndaa.pdf:\n",
      "clusion areas in the Indo-Pacific theater of operations. Peer adver-\n",
      "saries continue to advance in hypersonic technology, including re-\n",
      "usable systems, that pose a threat to U.S. national security inter-\n",
      "ests. \n",
      "However, the committee is concerned by the lack of research and \n",
      "development \n",
      "funding \n",
      "directed \n",
      "towards \n",
      "fielding \n",
      "a \n",
      "reusable \n",
      "hypersonic platform with aircraft-like operations and qualities. \n",
      "Therefore, the committee directs the Under Secretary of Defense\n",
      "----------------------------------------\n",
      "\n",
      "On Page 120 in /tmp/ndaa/ndaa.pdf:\n",
      "hypersonics workforce through the development of graduate and \n",
      "pre-doctoral degree programs; and \n",
      "(4) plans to increase funding for advanced hypersonics facilities \n",
      "for research and graduate-level education. \n",
      "Additionally, the committee recommends $543.9 million, an in-\n",
      "crease of $3.0 million, in PE 0601153N for hypersonic education ef-\n",
      "forts. \n",
      "Identifying innovation organizations \n",
      "The committee notes that with the success of the Defense Inno-\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "print('REFERENCES')\n",
    "print()\n",
    "for d in result['source_documents']:\n",
    "    print(f\"On Page {d.metadata['page']} in {d.metadata['source']}:\")\n",
    "    print(d.page_content)\n",
    "    print('----------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#|hide\n",
    "\n",
    "## Additional Tips\n",
    "\n",
    "The `LLM.ask`and `LLM.ingest` methods include many options for more complex scenarios.  \n",
    "\n",
    "#### LLM.ingest options\n",
    "\n",
    "- If supplying `infer_table_structure=True` to `LLM.ingest`, the `LLM.ask` method will consider tables within PDFs when answering questions. This behavior can be controlled with the `table_k` and `table_score_threshold` parameters in `LLM.ask`.\n",
    "- If suppyling `extract_document_titles=True` to `LLM.ingest`, the title of each document will be inferred and added to each document chunk for potentially better retrieval.\n",
    "- If supplying `caption_tables=True`, an LLM-generated caption will be added to every extracted table for potentially better table retrieval.\n",
    "- Increasing chunk size of sources for more answer context\n",
    "#### LLM.ask options\n",
    "- If supplying `selfask=True` as an argument, a [Self-Ask prompting strategy](https://learnprompting.org/docs/advanced/few_shot/self_ask) will be used to decompose the question into subquestions.\n",
    "- Adjusting prompts for QA with `prompt_template` argument to `LLM.ask`\n",
    "- Increasing number of sources to consider (`k` parameter to `LLM.ask`)\n",
    "- Filtering sources with `filters` and `where_document`\n",
    "- Adding a score threshold for sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
